{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import seaborn as sns\n",
    "\n",
    "#print('Running on PyMC3 v{}'.format(pm.__version__))\n",
    "\n",
    "# If you get an error like: non-constant-expression cannot be narrowed \n",
    "# then comment these lines out\n",
    "# If you know how to actually fix it, please let me know!\n",
    "#import theano\n",
    "#theano.config.gcc.cxxflags = \"-Wno-c++11-narrowing\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Saved Trace\n",
    "We can save traces off to disk and reload them later, and do all the post-sampling analysis and prediction on the re-loaded trace.\n",
    "\n",
    "This notebook shows how to do that.\n",
    "\n",
    "First, we will load the training dataset and a holdout dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observed_usage = pd.read_csv('data/training.csv').iloc[:,1:]\n",
    "holdout = pd.read_csv('data/holdout.csv').iloc[:,1:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to pull in a little bit of code from the original notebook. We need the data generation function of course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(Q, PI, th0, G, ALPHA, num_samples, renewal_period, force_no_churn, initial_state=None):\n",
    "\n",
    "    states = []\n",
    "    samples = []\n",
    "    events = []\n",
    "\n",
    "    # construct Theta vector from parameters\n",
    "    THETA = np.zeros(Q.shape[0])\n",
    "    THETA[0] = th0\n",
    "    for i in range(1,Q.shape[0]):\n",
    "        THETA[i] = THETA[i-1] + np.exp(G[i-1])\n",
    "    \n",
    "    for i in range(0,ALPHA.shape[0]):\n",
    "        if initial_state is None:\n",
    "            state = np.random.choice(Q.shape[0], 1, p=Q)[0]\n",
    "        else:\n",
    "            state = np.random.choice(Q.shape[0],1,p=PI[initial_state[i]])[0]     \n",
    "\n",
    "        churned = False\n",
    "        for j in range(0,num_samples):  \n",
    "\n",
    "            # if the force_no_churn flag is set, and churn condition met\n",
    "            # the choose a new state\n",
    "            if churned == False and force_no_churn == True and state == 0 and (j+1) % renewal_period == 0:\n",
    "                while state == 0:\n",
    "                    state = np.random.choice(Q.shape[0],1,p=PI[state])[0]\n",
    "\n",
    "            # save current state\n",
    "            states = np.append(states, state)\n",
    "\n",
    "            # usage calculation in current state\n",
    "            if churned == False:\n",
    "                lam = ALPHA[i] * THETA[state]\n",
    "                sample = np.random.poisson(lam=lam)\n",
    "            else:\n",
    "                sample = 0\n",
    "\n",
    "            # churn event in current state\n",
    "            if churned == False:\n",
    "                if state == 0 and (j+1) % renewal_period == 0:\n",
    "                    churned = True\n",
    "                    event = 1\n",
    "                else:\n",
    "                    event = 0\n",
    "            else:\n",
    "                event = 0\n",
    "\n",
    "            samples = np.append(samples, sample)\n",
    "            events = np.append(events, event)\n",
    "\n",
    "            # choose next state\n",
    "            if churned == False:\n",
    "                state = np.random.choice(Q.shape[0],1,p=PI[state])[0]\n",
    "            else:\n",
    "                state = 0\n",
    "\n",
    "    states = np.reshape(states, (ALPHA.shape[0], num_samples))\n",
    "    events = np.reshape(events, (ALPHA.shape[0], num_samples))\n",
    "    samples = np.reshape(samples, (ALPHA.shape[0], num_samples))\n",
    "    return [states, events, samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need our custom distribution classes, because we'll also need a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymc3.distributions.dist_math import bound\n",
    "\n",
    "class CommitmentProcess(pm.Categorical):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, PI=None, Q=None, renewal_mask=None, num_states=3, \n",
    "                 *args, **kwargs):\n",
    "        super(pm.Categorical, self).__init__(*args, **kwargs)\n",
    "        self.PI = PI\n",
    "        self.Q = Q\n",
    "        self.renewal_mask = renewal_mask\n",
    "        self.k = num_states\n",
    "        self.mode = tt.cast(0,dtype='int64')\n",
    "    \n",
    "    def logp(self, x):\n",
    "        \n",
    "        log_p = 0.\n",
    "        for i in range(0, self.shape[0]):\n",
    "            p_it = self.PI[x[i,][:-1]]\n",
    "            x_t = x[i,][1:]\n",
    "            x_0 = tt.stack([x[i,][0]])\n",
    "            mask = self.renewal_mask\n",
    "        \n",
    "            log_p_i = pm.Categorical.dist(self.Q).logp(x_0) + tt.sum(pm.Categorical.dist(p_it).logp(x_t))\n",
    "        \n",
    "            # Restrction: if not churned, cannot be in state 0 at a renewal period\n",
    "            log_p = log_p + bound(log_p_i, tt.dot(mask, x_t)>0)\n",
    "\n",
    "        return log_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UsageProcess(pm.Discrete):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=None, th0=None, G=None, states=None, num_states=3,\n",
    "                 *args, **kwargs):\n",
    "        super(UsageProcess, self).__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.th0 = th0\n",
    "        self.G = G\n",
    "        self.states = states\n",
    "        self.num_states = num_states\n",
    "        self.mean = 0.\n",
    "\n",
    "        \n",
    "    def logp(self, x):\n",
    "        states = self.states\n",
    "\n",
    "        # build theta vector from the components\n",
    "        theta = tt.concatenate([tt.stack([self.th0]), tt.exp(self.G)])\n",
    "        zero = tt.zeros_like(theta)\n",
    "        \n",
    "        for i in range(1, num_states):\n",
    "            theta = theta + tt.concatenate([zero[-i:], theta[0:self.num_states-i]])\n",
    "        \n",
    "        # build lambda matrix: theta is row vector, alpha is column\n",
    "        # labmda is the outer-product of the two\n",
    "        Lambda = tt.outer(self.alpha,theta)\n",
    "        \n",
    "        log_p = 0.\n",
    "        for i in range(0, self.shape[0]):\n",
    "            lam_it = Lambda[i][states[i,]]\n",
    "            y_it = x[i]\n",
    "            log_p_i = tt.sum(pm.Poisson.dist(mu=lam_it).logp(y_it))\n",
    "            \n",
    "            log_p = log_p + log_p_i\n",
    "\n",
    "        return log_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "We do have to define a model with the same variables, but we don't actually need to run sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "post_burn_in=1000\n",
    "\n",
    "renewal_period = 3\n",
    "num_states = 2\n",
    "\n",
    "num_custs = observed_usage.shape[0]\n",
    "obs_len = observed_usage.shape[1]\n",
    "renewal_mask = np.where(((np.arange(1,obs_len)+1) % renewal_period)!=0,0,1)\n",
    "\n",
    "states_test_val = np.ones((num_custs, obs_len))\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "    Q = pm.Dirichlet('Q', a=np.ones((num_states)) + 1., shape=(num_states))    \n",
    "    PI = pm.Dirichlet('PI', a=np.ones((num_states,num_states)) + 1., shape=(num_states,num_states))    \n",
    "    r = pm.Gamma('r', alpha=0.01, beta=0.01)\n",
    "    A = pm.Gamma('A',alpha=r, beta=r, shape=((num_custs)))    \n",
    "    th0 = pm.Uniform('th0',lower=0.0,upper=10.0)\n",
    "    G = pm.Normal('G',mu=np.zeros(num_states-1), sd=np.ones(num_states-1)*10000., shape=(num_states-1))\n",
    "\n",
    "    states = CommitmentProcess('states', PI=PI, Q=Q, renewal_mask = renewal_mask, num_states=num_states, shape=(num_custs,obs_len), testval=states_test_val)\n",
    "    usage = UsageProcess('usage', alpha=A, th0=th0, G=G, states=states, num_states=num_states, shape=(num_custs), observed=observed_usage)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Trace\n",
    "It's one line! And after it's loaded we can do analysis and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace = pm.backends.ndarray.load_trace('./traces/ta', model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Convergence\n",
    "From the paper\n",
    ">We burn-in the first 95,000 iterations and use the following 5,000 iterations to draw from the posterior marginal distributions. Convergence of the parameters was diagnosed visually, looking at the historical draws of all parameters, and also using the Gelman-Rubin statistic R, which compares the ratio of the pooled chain variance with the within chain variance, for a model estimated using multiple and disperse starting values.\n",
    "\n",
    "We can use the trace plot to visually diagnose convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#_ = pm.traceplot(trace[-post_burn_in:])\n",
    "\n",
    "#from pymc3.diagnostics import gelman_rubin\n",
    "#gelman_rubin(trace, include_transformed=True)\n",
    "\n",
    "#model_waic = pm.waic(trace, model=model, progressbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prediction\"></a>\n",
    "## Prediction\n",
    "Now that we've estimated the parameters of the model, we can use them to predict future customer behavior.\n",
    "\n",
    "### Point Estimate\n",
    "One source of estimates is to take the average of the trace values (ignoring some initial section of the trace, as \"burn-in\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q_avg = np.average(trace['Q'][-post_burn_in:],axis=0)\n",
    "PI_avg = np.average(trace['PI'][-post_burn_in:],axis=0)\n",
    "G_avg = np.average(trace['G'][-post_burn_in:],axis=0)\n",
    "th0_avg = np.average(trace['th0'][-post_burn_in:],axis=0)\n",
    "A_avg = np.average(trace['A'][-post_burn_in:],axis=0)\n",
    "last_state = np.floor(np.average(trace['states'][-post_burn_in:],axis=0)[:,-1] + 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Estimation\n",
    "Since the last time period in the data represents a renewal period, we can predict who will churn based on the estimate of the last state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can also plot a distribution for that estimated state to get an idea of the uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.distplot(trace['states'][-post_burn_in:,0,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take these paramater estimates and give them to the data generator to predict future states and usage. This is where the `initial_state` param comes in: we can use an estimate of the last state each customer was in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_periods = 3\n",
    "prediction = generate_data(Q_avg, PI_avg, th0_avg, G_avg, A_avg, prediction_periods, renewal_period, False, last_state)\n",
    "#np.reshape(prediction, (3, A_avg.shape[0], prediction_periods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the predictions with held out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(holdout.values, prediction[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from the Trace\n",
    "Instead of taking the average of the trace, we can iterate over the trace data and generate a prediction for each of the parameter values. This will give us a result that shows the uncertainty of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = []\n",
    "events = []\n",
    "usage = []\n",
    "\n",
    "prediction_periods = 3\n",
    "for i in range(post_burn_in):\n",
    "    Q_sample = trace['Q'][i]\n",
    "    PI_sample = trace['PI'][i]\n",
    "    G_sample = trace['G'][i]\n",
    "    th0_sample = trace['th0'][i]\n",
    "    A_sample = trace['A'][i]\n",
    "    last_observed_state = trace['states'][i][:,-1]\n",
    "    st, ev, us = generate_data(Q_sample, PI_sample, th0_sample, G_sample, A_sample, prediction_periods, renewal_period, False, last_observed_state )\n",
    "    states.append(st)\n",
    "    events.append(ev)\n",
    "    usage.append(us)\n",
    "    \n",
    "states = np.reshape(states, (post_burn_in, A_sample.shape[0], prediction_periods))\n",
    "events = np.reshape(events, (post_burn_in, A_sample.shape[0], prediction_periods))\n",
    "usage = np.reshape(usage, (post_burn_in, A_sample.shape[0], prediction_periods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a lot of possible outcomes. We can do things like plot the distribution of the predicted usage for one customer in a certain period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_id=7\n",
    "period=0\n",
    "_ = sns.distplot(usage[:,cust_id,period])\n",
    "_ = plt.axvline(x=holdout.iloc[cust_id,period], color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
