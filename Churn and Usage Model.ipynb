{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#print('Running on PyMC3 v{}'.format(pm.__version__))\n",
    "# If you get an error like: non-constant-expression cannot be narrowed \n",
    "# then comment these lines out\n",
    "# If you know how to actually fix it, please let me know!\n",
    "#import theano\n",
    "#theano.config.gcc.cxxflags = \"-Wno-c++11-narrowing\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Your Customers the Hard Way\n",
    "## A Tutorial\n",
    "by Anthony Alford, [genesys.com](https://www.genesys.com/)\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "### [Introduction](#introduction)\n",
    "\n",
    "### [Generative Model](#generative-model)\n",
    "\n",
    "### [PyMC3 Implementation](#pymc3-implementation)\n",
    "\n",
    "### [Prediction](#prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates [Ascarza and Hardie's model](https://www0.gsb.columbia.edu/.../4587/ascarza_hardie_churn.pdf) for customer usage and churn. The model consists of a latent *commitment* process, an observed *usage* process that is observed every time period, and *renewal* process that is observed every *n* periods.\n",
    "\n",
    "### Setup\n",
    "I've included a Docker file, two shell scripts, and a pip requirements file. The Docker file is based on the Jupyter Docker Stacks `scipy-notebook` image.\n",
    "\n",
    "If you'd like to run this notebook in Docker:\n",
    " * Open a terminal and `cd` to the directory where you cloned this repo\n",
    " * Execute the `build-docker.sh` shell script. This builds an image and tags it `churn-and-usage`. The image will have the packages listed in the [scipy-notebook documentation](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html#jupyter-scipy-notebook_) plus any listed in `requirements.txt`\n",
    " * Execute the `run-docker.sh` shell script. This wil start up a Docker container that is running Jupyter. It will also map the working directory (i.e., this repo) to a directory called `work`, where this notebook can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"generative-model\"></a>\n",
    "## Generative Model\n",
    "\n",
    "First we will code a function to model this process and generate some test data. Then we we will use PyMC3 to estimate the parameters of a model from data (both real and simulated).\n",
    "\n",
    "Notation (from Ascarza and Hardie, but with zero-based indexing):\n",
    "* $i$ denotes each customer: $i = {1, 2, \\ldots, I}$\n",
    "* $t$ denotes the usage time unit (periods). For each $i$, total of $T_i$ observations (note: for our purposes, all customers have the same number of observations)\n",
    "* $n$ is number of usage periods associated with a contract period\n",
    "\n",
    "\n",
    "At each time $t$, each customer $i$ has a latent commitment state $S_{it}$, which follows a Markov process, with $K$ states ${0, 1, \\ldots, K-1}$, with $0$ corresponding to the lowest level of commitment and $K-1$ to the highest. A customer's states change over time according to a transition matrix $\\Pi =\\{\\pi_{jk}\\}$, with $j, k \\in {1, \\dots, K}$. This process also models the renewal behavior: if a customer's latent state is 0 at a renewal period, the customer will churn.\n",
    "\n",
    "The probability that customer $i$ is in commitment state $k$ at beginning of its lifetime is determined by the vector $Q = \\{q_1 ,\\ldots, q_K \\}$\n",
    "\n",
    "For a customer in in state $k$, the usage process generates an observed value (e.g., number of purchase) in period $t$. The observation is drawn from a Poisson distribution with a parameter $\\lambda_{it}$ that is composed of a state dependent parameter $\\theta_k$ that varies depending on the underlying level of commitment (which varies over time) and an individual specific parameter $\\alpha_i$ that remains constant over time. Thus: $ \\lambda_{it}~\\big|~[S_{it}=k]~=~\\alpha_i\\theta_k $\n",
    "\n",
    "The vector $\\boldsymbol\\theta = \\{\\theta_k\\}, k = 1, \\ldots, K$ of state-specific parameters allows the each customerâ€™s mean usage levels to change over time. In order to satisfy the condition $$0 < \\theta_1<\\theta_2<\\ldots<\\theta_K $$ the vector components are reparameterized as $$ \\theta_{\\tau}~=~\\theta_{\\tau-1} + e^{\\gamma_\\tau}, ~~\\forall~\\tau > 1$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Data - Parameters\n",
    "To simulate data, we need the following parameters:\n",
    "* Q - vector of the initial state probabilities ($Q$)\n",
    "* PI - transition matrix for the Markov process ($\\Pi$)\n",
    "* THETA - vector of state-dependentent usage parameters ($\\boldsymbol\\theta$), composed of\n",
    " * th0 - state zero usage parameter ($\\theta_0$)\n",
    " * g1, g2, etc - higher-state usage parameters ($\\gamma_{\\tau}$)\n",
    "* A - vector customer specific usage parameters ($\\alpha_i$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q_actual=np.array([0.0, 0.50, 0.50])\n",
    "\n",
    "PI_actual=np.array([[0.85, 0.15, 0.0],\n",
    "       [0.2, 0.55, 0.25],\n",
    "       [0.0, 0.45, 0.55]])\n",
    "\n",
    "\n",
    "th0_actual=5.0\n",
    "G_actual = np.array([2.5, 3.0])\n",
    "\n",
    "\n",
    "A_actual=np.array([5.0, 10.0, 7.0, 20.0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Data - Generation Function\n",
    "This function implements the model described above. It outputs three numpy arrays:\n",
    "* The (unobserved) states for each customer \n",
    "* The churn events (if any) for each customer\n",
    "* The observed usage for each customer\n",
    "\n",
    "Each array's shape is $(I,T)$. That is: one row for each customer and one column for each time period observed. We are using a common observation window for all customers.\n",
    "\n",
    "Besides the model parameters listed above, the function also has a flag to \"force\" the generation of non-churning customer data. In other words, we can use it to simulate data where no customers churn. This was handy for simulating a set of customers with a common observation window.\n",
    "\n",
    "The function can also be given an initial set of states for each customer. This might be handy later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(Q, PI, th0, G, ALPHA, num_samples, renewal_period, force_no_churn, initial_state=None):\n",
    "\n",
    "    states = []\n",
    "    samples = []\n",
    "    events = []\n",
    "\n",
    "    # construct Theta vector from parameters\n",
    "    THETA = np.zeros(Q.shape[0])\n",
    "    THETA[0] = th0\n",
    "    for i in range(1,Q.shape[0]):\n",
    "        THETA[i] = THETA[i-1] + np.exp(G[i-1])\n",
    "    \n",
    "    for i in range(0,ALPHA.shape[0]):\n",
    "        if initial_state is None:\n",
    "            state = np.random.choice(Q.shape[0], 1, p=Q)[0]\n",
    "        else:\n",
    "            state = np.random.choice(Q.shape[0],1,p=PI[initial_state[i]])[0]     \n",
    "\n",
    "        churned = False\n",
    "        for j in range(0,num_samples):  \n",
    "\n",
    "            # if the force_no_churn flag is set, and churn condition met\n",
    "            # the choose a new state\n",
    "            if churned == False and force_no_churn == True and state == 0 and (j+1) % renewal_period == 0:\n",
    "                while state == 0:\n",
    "                    state = np.random.choice(Q.shape[0],1,p=PI[state])[0]\n",
    "\n",
    "            # save current state\n",
    "            states = np.append(states, state)\n",
    "\n",
    "            # usage calculation in current state\n",
    "            if churned == False:\n",
    "                lam = ALPHA[i] * THETA[state]\n",
    "                sample = np.random.poisson(lam=lam)\n",
    "            else:\n",
    "                sample = 0\n",
    "\n",
    "            # churn event in current state\n",
    "            if churned == False:\n",
    "                if state == 0 and (j+1) % renewal_period == 0:\n",
    "                    churned = True\n",
    "                    event = 1\n",
    "                else:\n",
    "                    event = 0\n",
    "            else:\n",
    "                event = 0\n",
    "\n",
    "            samples = np.append(samples, sample)\n",
    "            events = np.append(events, event)\n",
    "\n",
    "            # choose next state\n",
    "            if churned == False:\n",
    "                state = np.random.choice(Q.shape[0],1,p=PI[state])[0]\n",
    "            else:\n",
    "                state = 0\n",
    "\n",
    "    states = np.reshape(states, (ALPHA.shape[0], num_samples))\n",
    "    events = np.reshape(events, (ALPHA.shape[0], num_samples))\n",
    "    samples = np.reshape(samples, (ALPHA.shape[0], num_samples))\n",
    "    return [states, events, samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's get some simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_observations = 12\n",
    "renewal_period = 3\n",
    "\n",
    "observed_usage = np.array(generate_data(Q_actual, PI_actual, th0_actual, G_actual, A_actual, \n",
    "                                     total_observations, renewal_period, True)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pymc3-implementation\"></a>\n",
    "## PyMC3 Implementation\n",
    "\n",
    "To implement the model in PyMC3, we need two custom distributions, for the commitment process and the usage process respectively. We'll create Python classes to represent these, passing the appropriate values to the constructor, and implementing the `logp` method to calculate the log-likelihood.\n",
    "\n",
    "NOTE: in developing this part of the code, I found [Helmut Strey's Hidden Markov Model repo](https://github.com/hstrey/Hidden-Markov-Models-pymc3) invaluable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Committment Process\n",
    "The commitment process also includes the renewal or process:\n",
    ">We use the categorical distribution...to draw the augmented states, and control for the path restrictions (due to the contractual specification) by truncating the categorical distribution function in the renewal periods (t = 1, n + 1, 2n + 1, ..).\n",
    "\n",
    "In other words, if a customer has not been observed to churn in a past renewal period, the customer *cannot* have been in state 0. This implies that `logp` should be -Inf, so we use the `bound` function. To make that logic work with linear algebra, we pass in a \"mask\" vector, which is length $T-1$. It represents the time periods (starting from the second, or $t=1$, period) where renewal is possible: 1 at renewal periods and 0 everywhere else. We know a valid customer state history cannot be in state $s=0$ at those points. Therefore, if we take the dot product of a customers vector of state history with this mask must always be 0 for a valid state history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymc3.distributions.dist_math import bound\n",
    "\n",
    "class CommitmentProcess(pm.Categorical):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, PI=None, Q=None, renewal_mask=None, num_states=3, \n",
    "                 *args, **kwargs):\n",
    "        super(pm.Categorical, self).__init__(*args, **kwargs)\n",
    "        self.PI = PI\n",
    "        self.Q = Q\n",
    "        self.renewal_mask = renewal_mask\n",
    "        self.k = num_states\n",
    "        self.mode = tt.cast(0,dtype='int64')\n",
    "    \n",
    "    def logp(self, x):\n",
    "        \n",
    "        log_p = 0.\n",
    "        for i in range(0, self.shape[0]):\n",
    "            p_it = self.PI[x[i,][:-1]]\n",
    "            x_t = x[i,][1:]\n",
    "            x_0 = tt.stack([x[i,][0]])\n",
    "            mask = self.renewal_mask\n",
    "        \n",
    "            log_p_i = pm.Categorical.dist(self.Q).logp(x_0) + tt.sum(pm.Categorical.dist(p_it).logp(x_t))\n",
    "        \n",
    "            # Restrction: if not churned, cannot be in state 0 at a renewal period\n",
    "            log_p = log_p + bound(log_p_i, tt.dot(mask, x_t)>0)\n",
    "\n",
    "        return log_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage Process\n",
    "\n",
    "Customer's usage likelihood:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "L(\\boldsymbol{\\theta}, \\alpha_i~\\big|~\\tilde{S_i}=\\tilde{s_i},data) &= \\prod_{t=1}^{T_i} P(Y_{it}=y_{it}~\\big|~S_{it}=k,\\boldsymbol{\\theta},\\alpha_i) \\\\\n",
    "&= \\prod_{t=1}^{T_i} \\frac{e^{-\\alpha_i\\theta_i}(\\alpha_i\\theta_k)^{y_{it}} }{y_{it}!} \\\\\n",
    "&= \\prod_{t=1}^{T_i} \\frac{e^{-\\lambda_{it}}(\\lambda_{it})^{y_{it}} }{y_{it}!} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "Which is just the Poisson likelihood, with a different lambda for each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UsageProcess(pm.Discrete):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=None, th0=None, G=None, states=None, num_states=3,\n",
    "                 *args, **kwargs):\n",
    "        super(UsageProcess, self).__init__(*args, **kwargs)\n",
    "        self.alpha = alpha\n",
    "        self.th0 = th0\n",
    "        self.G = G\n",
    "        self.states = states\n",
    "        self.num_states = num_states\n",
    "        self.mean = 0.\n",
    "\n",
    "        \n",
    "    def logp(self, x):\n",
    "        states = self.states\n",
    "\n",
    "        # build theta vector from the components\n",
    "        theta = tt.concatenate([tt.stack([self.th0]), tt.exp(self.G)])\n",
    "        zero = tt.zeros_like(theta)\n",
    "        \n",
    "        for i in range(1, num_states):\n",
    "            theta = theta + tt.concatenate([zero[-i:], theta[0:self.num_states-i]])\n",
    "        \n",
    "        # build lambda matrix: theta is row vector, alpha is column\n",
    "        # labmda is the outer-product of the two\n",
    "        Lambda = tt.outer(self.alpha,theta)\n",
    "        \n",
    "        log_p = 0.\n",
    "        for i in range(0, self.shape[0]):\n",
    "            lam_it = Lambda[i][states[i,]]\n",
    "            y_it = x[i]\n",
    "            log_p_i = tt.sum(pm.Poisson.dist(mu=lam_it).logp(y_it))\n",
    "            \n",
    "            log_p = log_p + log_p_i\n",
    "\n",
    "        return log_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyMC3 Model\n",
    "We are now ready to use PyMC3 to estimate the model parameters. First, we'll setup the priors. From the paper:\n",
    "* $Q$ and $\\Pi$: Dirichlet prior with equal probabilities\n",
    "* $\\alpha_i$: gamma distribution with shape and scale parameter r\n",
    "* $r$: diffuse gamma distribution prior (shape and scale parameters being 0.01)\n",
    "* $\\theta_0$: uniform prior over the interval (0,10) \n",
    "* $\\gamma_\\tau$: diffuse normal priors (with mean 0 and variance 10000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sampling params\n",
    "chains = 1\n",
    "draws = 3000\n",
    "post_burn_in = 1000\n",
    "\n",
    "# Model params\n",
    "num_states = 3\n",
    "num_custs = observed_usage.shape[0]\n",
    "obs_len = observed_usage.shape[1]\n",
    "renewal_mask = np.where(((np.arange(1,obs_len)+1) % renewal_period)!=0,0,1)\n",
    "\n",
    "# This lets us avoid trying out a lot of invalid state possibilities\n",
    "states_test_val = np.ones((num_custs, obs_len))\n",
    "\n",
    "from scipy import optimize\n",
    "with pm.Model() as model:\n",
    "    Q = pm.Dirichlet('Q', a=np.ones((num_states)) + 1., shape=(num_states))    \n",
    "    PI = pm.Dirichlet('PI', a=np.ones((num_states,num_states)) + 1., shape=(num_states,num_states))    \n",
    "    r = pm.Gamma('r', alpha=0.01, beta=0.01)\n",
    "    A = pm.Gamma('A',alpha=r, beta=r, shape=((num_custs)))    \n",
    "    th0 = pm.Uniform('th0',lower=0.0,upper=10.0)\n",
    "    G = pm.Normal('G',mu=np.zeros(num_states-1), sd=np.ones(num_states-1)*10000., shape=(num_states-1))\n",
    "\n",
    "    states = CommitmentProcess('states', PI=PI, Q=Q, renewal_mask = renewal_mask, num_states=num_states, shape=(num_custs,obs_len), testval=states_test_val)\n",
    "    usage = UsageProcess('usage', alpha=A, th0=th0, G=G, states=states, num_states=num_states, shape=(num_custs), observed=observed_usage)\n",
    "    \n",
    "    start = pm.find_MAP(method='Powell')\n",
    "    step1 = pm.Metropolis(vars=[r,PI,Q,A,G,th0,usage])\n",
    "    step2 = pm.CategoricalGibbsMetropolis(vars=[states])\n",
    "    trace = pm.sample(draws, start=start, step=[step1,step2], chains=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Trace\n",
    "We can save the trace to a file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pm.backends.ndarray.save_trace(trace, directory='./traces/trace1', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Convergence\n",
    "From the paper\n",
    ">We burn-in the first 95,000 iterations and use the following 5,000 iterations to draw from the posterior marginal distributions. Convergence of the parameters was diagnosed visually, looking at the historical draws of all parameters, and also using the Gelman-Rubin statistic R, which compares the ratio of the pooled chain variance with the within chain variance, for a model estimated using multiple and disperse starting values.\n",
    "\n",
    "We can use the trace plot to visually diagnose convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = pm.traceplot(trace[-post_burn_in:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prediction\"></a>\n",
    "## Prediction\n",
    "Now that we've estimated the parameters of the model, we can use them to predict future customer behavior.\n",
    "\n",
    "### Point Estimate\n",
    "One source of estimates is to take the average of the trace values (ignoring some initial section of the trace, as \"burn-in\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q_avg = np.average(trace['Q'][-post_burn_in:],axis=0)\n",
    "PI_avg = np.average(trace['PI'][-post_burn_in:],axis=0)\n",
    "G_avg = np.average(trace['G'][-post_burn_in:],axis=0)\n",
    "th0_avg = np.average(trace['th0'][-post_burn_in:],axis=0)\n",
    "A_avg = np.average(trace['A'][-post_burn_in:],axis=0)\n",
    "last_observed_state = np.floor(np.average(trace['states'][-post_burn_in:],axis=0)[:,-1] + 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take these paramater estimates and give them to the data generator to predict future states and usage. This is where the `initial_state` param comes in: we can use an estimate of the last state each customer was in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_periods = 3\n",
    "prediction = generate_data(Q_avg, PI_avg, th0_avg, G_avg, A_avg, prediction_periods, renewal_period, False, last_observed_state)\n",
    "np.reshape(prediction, (3, A_avg.shape[0], prediction_periods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from the Trace\n",
    "Instead of taking the average of the trace, we can iterate over the trace data and generate a prediction for each of the parameter values. This will give us a result that shows the uncertainty of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = []\n",
    "events = []\n",
    "usage = []\n",
    "\n",
    "prediction_periods = 3\n",
    "for i in range(post_burn_in):\n",
    "    Q_sample = trace['Q'][i]\n",
    "    PI_sample = trace['PI'][i]\n",
    "    G_sample = trace['G'][i]\n",
    "    th0_sample = trace['th0'][i]\n",
    "    A_sample = trace['A'][i]\n",
    "    last_observed_state = trace['states'][i][:,-1]\n",
    "    st, ev, us = generate_data(Q_sample, PI_sample, th0_sample, G_sample, A_sample, prediction_periods, renewal_period, False, last_observed_state )\n",
    "    states.append(st)\n",
    "    events.append(ev)\n",
    "    usage.append(us)\n",
    "    \n",
    "states = np.reshape(states, (post_burn_in, A_sample.shape[0], prediction_periods))\n",
    "events = np.reshape(events, (post_burn_in, A_sample.shape[0], prediction_periods))\n",
    "usage = np.reshape(usage, (post_burn_in, A_sample.shape[0], prediction_periods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a lot of possible outcomes. We can do things like plot the distribution of the usage for one customer in a certain period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = sns.distplot(usage[:,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we can look at the probability of the customers churning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.average(events, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
